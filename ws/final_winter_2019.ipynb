{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "upset-asset",
   "metadata": {},
   "source": [
    "### Problem 2\n",
    "\n",
    "This question asks you to do a Monte Carlo simulation using the setup from Problem 1. The idea is to compare finite sample properties of the OLS estimator $\\hat{\\beta}_1$ and the alternative estimator $\\tilde{\\beta}_1$.\n",
    "\n",
    "Please attach your code to the solutions. In addition to providing the code, please write down separate answers for each part of the problem. For example, to answer part (a), write down what the approximate means, standard deviations, and mean squared errors of the estimators are. We should be able to check the correctness of your solutions without looking at the code.\n",
    "\n",
    "Suppose $e_i , v_i , w_i$ , and $x_i^*$ are mutually independent. Also suppose that $x_i^* \\sim N(1, 1)$ and $e_i , v_i , w_i \\sim N (0, 0.5)$. Let $\\beta_1 = 2$ and $\\beta_2 = 3$. The sample size is $n = 200$. Now do the following at least 1.000 times."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "falling-league",
   "metadata": {},
   "source": [
    "***\n",
    "\n",
    "#### *Remark on implementation:*\n",
    "\n",
    "In most situations it suffices to loop over simulation runs. Here I don't loop over simulations but include the simulations in the array creation directly. This is usually faster and often times easier to read; however, it can also lead to overlooked errors, as the dimensionality of the arrays can easily grow to 3 or 4.\n",
    "\n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "sophisticated-above",
   "metadata": {},
   "source": [
    "   1. Use the distributions and parameters given above as well as the model in Problem 1 to generate a random sample $\\{y_i , x_i , z_i \\}_{i=1}^n$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "administrative-diploma",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "handed-appointment",
   "metadata": {},
   "outputs": [],
   "source": [
    "beta_1 = 2\n",
    "\n",
    "def outcome(x_star, e, beta_1=beta_1, beta_2=3):\n",
    "    y = beta_1 * x_star + beta_2 + e\n",
    "    return y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "indie-lawsuit",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_random_sample(n_samples, n_simulations, seed=0):\n",
    "    np.random.seed(seed)\n",
    "    \n",
    "    x_star = np.random.normal(1, 1, size=(n_samples, n_simulations))\n",
    "    e, v, w = (np.random.normal(0, 0.5, size=(n_samples, n_simulations)) for _ in range(3))\n",
    "    x = x_star + v\n",
    "    z = x_star + w\n",
    "    y = outcome(x_star, e)\n",
    "    \n",
    "    return y, x, x_star, z, e, v, w"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "impossible-sheffield",
   "metadata": {},
   "source": [
    "   2. Obtain $\\hat{\\beta}$ and $\\tilde{\\beta}$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "affiliated-field",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_beta_1_hat(y, x):\n",
    "    x_mean = x.mean(axis=0)\n",
    "    y_mean = y.mean(axis=0)\n",
    "    xy_mean = (x * y).mean(axis=0)\n",
    "    xx_mean = (x ** 2).mean(axis=0)    \n",
    "    \n",
    "    beta = (xy_mean - x_mean * y_mean) / (xx_mean - x_mean ** 2)\n",
    "    return beta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "immune-advice",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_beta_1_tilde(y, x, z):\n",
    "    z_centered = z - z.mean(axis=0)\n",
    "    \n",
    "    beta = (z_centered * y).mean(axis=0) / (z_centered * x).mean(axis=0)\n",
    "    return beta"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "athletic-airline",
   "metadata": {},
   "source": [
    "   3. Construct the usual 95% confidence interval for $\\beta_1$ based on the OLS estimator.\n",
    "   \n",
    "\n",
    "For this I need functions which estimate the error variance, which in turn needs calculation of the predicted values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "painful-guest",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_beta_2(y, x, beta_1):\n",
    "    beta_2 = y.mean(axis=0) - beta_1 * x.mean(axis=0)\n",
    "    return beta_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "separate-management",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_ols_residuals(y, x, beta_1, beta_2):\n",
    "    residuals = y - beta_1 * x - beta_2\n",
    "    return residuals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "stopped-fantasy",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_ols_standard_error(residuals, x):\n",
    "    error_estimate = (residuals ** 2).mean(axis=0)\n",
    "    se = np.sqrt(error_estimate * np.var(x, axis=0))\n",
    "    return se"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "transparent-lithuania",
   "metadata": {},
   "outputs": [],
   "source": [
    "def confidence_interval(beta_1, se, n_samples, crit_value=.95):\n",
    "    const = 1.96 * se / np.sqrt(n_samples)\n",
    "    left = beta_1 - const\n",
    "    right = beta_1 + const\n",
    "    ci = np.c_[left, right]\n",
    "    return ci"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "secure-mineral",
   "metadata": {},
   "source": [
    "   4. Construct a 95% confidence interval for $\\beta_1$ based on $\\tilde{\\beta_1}$ and the results in part (e) of Problem 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "handy-encyclopedia",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_tilde_standard_error(residuals, x, z):\n",
    "    z_mean = z.mean(axis=0)\n",
    "    x_mean = x.mean(axis=0)\n",
    "    \n",
    "    cov_xz = (x * z).mean(axis=0) - z_mean * x_mean\n",
    "    \n",
    "    tmp = (z - z_mean) ** 2 * (residuals ** 2)\n",
    "    \n",
    "    se = np.sqrt(tmp.mean(axis=0)) / cov_xz\n",
    "    return se"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "engaging-johnston",
   "metadata": {},
   "source": [
    "### Actual Computation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "abstract-return",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_samples = 200\n",
    "n_simulations = 100_000\n",
    "\n",
    "y, x, x_star, z, e, v, w = generate_random_sample(n_samples, n_simulations)\n",
    "\n",
    "beta_1_hat = compute_beta_1_hat(y, x)\n",
    "beta_2_hat = compute_beta_2(y, x, beta_1_hat)\n",
    "residuals_hat = compute_ols_residuals(y, x, beta_1_hat, beta_2_hat)\n",
    "se_hat = compute_ols_standard_error(residuals_hat, x)\n",
    "\n",
    "beta_1_tilde = compute_beta_1_tilde(y, x, z)\n",
    "beta_2_tilde = compute_beta_2(y, x, beta_1_tilde)\n",
    "residuals_tilde = compute_ols_residuals(y, x, beta_1_tilde, beta_2_tilde)\n",
    "se_tilde = compute_tilde_standard_error(residuals_tilde, x, z)\n",
    "\n",
    "ci_hat = confidence_interval(beta_1_hat, se_hat, n_samples)\n",
    "ci_tilde = confidence_interval(beta_1_tilde, se_tilde, n_samples)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "metric-question",
   "metadata": {},
   "source": [
    "5. Now answer the following questions:\n",
    "\n",
    "    1. What are the approximate means, standard deviations, and mean squared errors of the estimators $\\hat{\\beta_1}$ and $\\tilde{\\beta_1}$? Which estimator do you prefer?\n",
    "\n",
    "    2. What is the coverage probability of the confidence interval based on the OLS estimator $\\hat{\\beta_1}$  ? In particular, how often is ${\\beta_1}$  in the confidence interval?\n",
    "\n",
    "    3. What is the coverage probability of the confidence interval based on the estimator $\\tilde{\\beta_1}$ ? In particular, how often is ${\\beta_1}$ in the confidence interval?\n",
    "\n",
    "    4. Discuss if the simulation results are in line with the theoretical properties you derived in Problem 1."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "superior-massage",
   "metadata": {},
   "source": [
    "## A:\n",
    "\n",
    "#### Hat Estimator:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "composed-directory",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.5999493691160271"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "beta_1_hat.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "lasting-headquarters",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.06522993965920468"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "beta_1_hat.std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "suburban-courtesy",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.16429545229860842"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "((beta_1_hat - beta_1) ** 2).mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "accepted-hardware",
   "metadata": {},
   "source": [
    "#### Tilde Estimator:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "crude-stewart",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.0034079524442654"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "beta_1_tilde.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "sensitive-dynamics",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.08966781895365132"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "beta_1_tilde.std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "square-diesel",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.008051931895767169"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "((beta_1_tilde - beta_1) ** 2).mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "loose-vampire",
   "metadata": {},
   "source": [
    "## B:\n",
    "\n",
    "#### Hat Estimator:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "third-theorem",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.00015"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "((ci_hat[:, 0] < beta_1) & (beta_1 < ci_hat[:, 1])).mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "informed-dominant",
   "metadata": {},
   "source": [
    "## C:\n",
    "#### Tilde Estimator:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "confirmed-import",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.94479"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "((ci_tilde[:, 0] < beta_1) & (beta_1 < ci_tilde[:, 1])).mean()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
